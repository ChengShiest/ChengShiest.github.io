<!DOCTYPE html>
<html>
<head>
    <title>Cheng Shi</title>

    <!-- Meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Styles -->
    <style>
          body {
            font-family: 'sans-serif';
            font-size: 16px;
            background-color: #FFFFFF;
            color: #4F6071;
          }
          #header {
            background-color: #f4f4f4;
            /*background-color: #FFFFFF;*/
            display: flex;
            align-items: flex-end;
            padding-top:60px;
            padding-bottom:60px;
          }
          #footer {
            background-color: #FFFFFF;
            padding:60px;
          }
          #portrait {
            border: 3px solid white;
          }
          #header-text {
            margin-top: 60px;
            margin-left: 220px;
          }
          #header-text-name {
            font-size: 40px;
          }
          #header-text-email {
            font-size: 20px;
            font-style: italic;
          }
          .header-text-desc {
            font-size: 20px;
          }
          .vspace-top {
            margin-top: 30px;
          }
          .vspace-top-news {
              margin-top: 15px;
          }
          .paper-image {
            width: 150px;
          }
          .news-date {
              font-weight: bold;
          }
          .paper-title {
            font-weight: bold;
          }
          .paper-authors {
            font-style: italic;
          }
    </style>
</head>

<body>
    <div id='header'>
        <div class='container'>
            <div class='row'>
                <div class="col-sm-2 offset-sm-1">
                    <img src='imgs/portrait.jpg' class='img-fluid'>
                </div>

                <div class="col">
                  <div id='header-text-name'>
                      Cheng Shi (石骋)
                  </div>
                  <div id='header-text-email'>
                        shicheng2022 (at) shanghaitech.edu.cn
                  </div>
                  <div>
                    <a href="https://github.com/ChengShiest">[GitHub]</a>
<!--                     <a href="https://scholar.google.com/citations?user=fuR1FBwAAAAJ&hl=en">[Google Scholar]</a>
                    <a href="docs/Anpei_CV.pdf">[Download CV]</a> -->
                  </div>

                </div>
            </div>
        </div>
    </div>


    <div class='container'>
        <div class='row vspace-top'>
            <div class='col offset-sm-1'>
                <h1>Bio</h1>
                <p>

                    I am a second-year Master stduent at the <a href="https://faculty.sist.shanghaitech.edu.cn/yangsibei/">Soolab</a> in <a href="https://www.shanghaitech.edu.cn/">ShanghaiTech University</a> advised by Prof. <a href="https://faculty.sist.shanghaitech.edu.cn/yangsibei/">Sibei Yang</a>. Previously, I obtained my Bachelor's degree from the ShanghaiTech University in 2022.
                    My research interests lie at the computer vision, natural language processing, and the intersection of them. My current research focuses on open-vocabulary detection and prompt tuning for Vision-Language models.

                </p>

                <div class='vspace-top'>
                    <h1>Publications</h1>
                </div>

                <p> * denotes equal contribution and † corresponding author</p>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='logo/img/can_intro.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            LoGoPrompt: Synthetic Text Images Can Be Good Visual Prompts for Vision-Language Models
                        </div>
                        <div class='paper-desc'>
                             ICCV 2023
                        </div>
                        <div class='paper-authors'>
                            <b>Cheng Shi</b>, and Sibei Yang†
                        </div>
                        <div>
                            <a href="https://chengshiest.github.io/logo/">[Project page]</a>
                            <a href="docs/04706.pdf">[Paper]</a>
                            <!-- <a href="https://chengshiest.github.io/logo/">[Code]</a> -->
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='edadet/img/eda_p5.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            EdaDet: Open-Vocabulary Object Detection Using Early Dense Alignment
                        </div>
                        <div class='paper-desc'>
                             ICCV 2023
                        </div>
                        <div class='paper-authors'>
                            <b>Cheng Shi</b>, and Sibei Yang†
                        </div>
                        <div>
                            <a href="https://chengshiest.github.io/edadet">[Project page]</a>
                            <a href="docs/02613.pdf">[Paper]</a>
                            <!-- <a href="https://chengshiest.github.io/edadet">[Code]</a> -->
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='edadet/img/cgformer.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Contrastive Grouping with Transformer for Referring Image Segmentation
                        </div>
                        <div class='paper-desc'>
                             CVPR 2023
                        </div>
                        <div class='paper-authors'>
                            Jiajin Tang, Ge Zheng, <b>Cheng Shi</b>, and Sibei Yang†
                        </div>
                        <div>
                            <!-- <a href="https://chengshiest.github.io/edadet">[Project page]</a> -->
                            <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Contrastive_Grouping_With_Transformer_for_Referring_Image_Segmentation_CVPR_2023_paper.pdf">[Paper]</a>
                            <a href="https://github.com/Toneyaya/CGFormer">[Code]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='edadet/img/dreamface.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance
                        </div>
                        <div class='paper-desc'>
                            SIGGRAPH 2023
                        </div>
                        <div class='paper-authors'>
                            Longwen Zhang*, Qiwei Qiu*, Hongyang Lin*, Qixuan Zhang, <b>Cheng Shi</b>, Wei Yang, Ye Shi, Sibei Yang†, Lan Xu†, Jingyi Yu†
                        </div>
                        <div>
                            <a href="https://sites.google.com/view/dreamface">[Project page]</a>
                            <a href="https://arxiv.org/abs/2304.03117">[Paper]</a>
                            <a href="https://www.youtube.com/watch?v=yCuvzgGMvPM">[Video]</a>
                        </div>
                    </div>
                </div>

                <div class='row vspace-top'>
                    <div class="col-sm-3">
                        <img src='edadet/img/eru.png' class='img-fluid'>
                    </div>

                    <div class="col">
                        <div class='paper-title'>
                            Spatial and Visual Perspective-Taking via View Rotation and Relation Reasoning for Embodied Reference Understanding
                        </div>
                        <div class='paper-desc'>
                             ECCV 2022
                        </div>
                        <div class='paper-authors'>
                            <b>Cheng Shi</b>, and Sibei Yang†
                        </div>
                        <div>
                            <!-- <a href="https://chengshiest.github.io/edadet">[Project page]</a> -->
                            <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136960199.pdf">[Paper]</a>
                            <a href="https://github.com/ChengShiest/REP-ERU">[Code]</a>
                        </div>
                    </div>
                </div>

            </div>
            
        </div>
    </div>



                

    <div id='footer' class='vspace-top'>
    <div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>
